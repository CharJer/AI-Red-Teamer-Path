{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def3b8eb-a152-4c94-a117-c5d97749be8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download successful\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# DATASET STAGE\n",
    "\n",
    "# URL of the dataset - skills assessment data\n",
    "url = \"https://academy.hackthebox.com/storage/modules/292/skills_assessment_data.zip\"\n",
    "# Download the dataset\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    print(\"Download successful\")\n",
    "else:\n",
    "    print(\"Failed to download the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31bafd5d-38ef-42fb-ac91-6557f629162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction successful\n"
     ]
    }
   ],
   "source": [
    "# Extract the dataset - skills_assessment_data - the code will put the .zip by itself\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "    z.extractall(\"skills_assessment_data\")\n",
    "    print(\"Extraction successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7ffc55-52c4-4e00-af6d-aed8624def5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['test.json', 'train.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List the extracted files from skills_assessment_data\n",
    "extracted_files = os.listdir(\"skills_assessment_data\")\n",
    "print(\"Extracted files:\", extracted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856b84dc-c922-4025-842e-a7d7db533584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "                                                text  label\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
      "1  Homelessness (or Houselessness as George Carli...      1\n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
      "3  This is easily the most underrated film inn th...      1\n",
      "4  This is not the typical Mel Brooks film. It wa...      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Only Load the Train JSON files into pandas DataFrames\n",
    "train_df = pd.read_json(\"skills_assessment_data/train.json\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"Train dataset:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5abebfa-7452-41d5-8d3f-834c7084b01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries for train: 96\n"
     ]
    }
   ],
   "source": [
    "# Print duplicate and it will drop if there's any\n",
    "print(\"Duplicate entries for train:\", train_df.duplicated().sum())\n",
    "train_df = train_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b9033e-ec1c-47e8-b651-41de3e30ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "                                                text  label\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
      "1  Homelessness (or Houselessness as George Carli...      1\n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
      "3  This is easily the most underrated film inn th...      1\n",
      "4  This is not the typical Mel Brooks film. It wa...      1\n",
      "              label\n",
      "count  24904.000000\n",
      "mean       0.500803\n",
      "std        0.500009\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        1.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24904 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    24904 non-null  object\n",
      " 1   label   24904 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 583.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show first few rows to see what have we done so far\n",
    "print(\"Train dataset:\")\n",
    "print(train_df.head())\n",
    "print(train_df.describe())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6e9fcd-0a88-4cd9-a249-78aecbe16bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEFORE ANY PREPROCESSING ===\n",
      "                                                text  label\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
      "1  Homelessness (or Houselessness as George Carli...      1\n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...      1\n",
      "3  This is easily the most underrated film inn th...      1\n",
      "4  This is not the typical Mel Brooks film. It wa...      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/carlomagno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/carlomagno/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/carlomagno/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# PREPROCESSING STAGE\n",
    "\n",
    "# Download the necessary NLTK data files\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "print(\"=== BEFORE ANY PREPROCESSING ===\") \n",
    "print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e15f282-78d8-45fb-9a59-48ff778c676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AFTER LOWERCASING ===\n",
      "0    bromwell high is a cartoon comedy. it ran at t...\n",
      "1    homelessness (or houselessness as george carli...\n",
      "2    brilliant over-acting by lesley ann warren. be...\n",
      "3    this is easily the most underrated film inn th...\n",
      "4    this is not the typical mel brooks film. it wa...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert all message text to lowercase\n",
    "train_df[\"text\"] = train_df[\"text\"].str.lower()\n",
    "print(\"\\n=== AFTER LOWERCASING ===\")\n",
    "print(train_df[\"text\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c406e9-9a68-4304-8177-fa1083f2735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AFTER REMOVING PUNCTUATION & NUMBERS (except $ and !) ===\n",
      "0    bromwell high is a cartoon comedy it ran at th...\n",
      "1    homelessness or houselessness as george carlin...\n",
      "2    brilliant overacting by lesley ann warren best...\n",
      "3    this is easily the most underrated film inn th...\n",
      "4    this is not the typical mel brooks film it was...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Remove non-essential punctuation and numbers, keep useful symbols like $ and !\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(lambda x: re.sub(r\"[^a-z\\s$!]\", \"\", x))\n",
    "print(\"\\n=== AFTER REMOVING PUNCTUATION & NUMBERS (except $ and !) ===\")\n",
    "print(train_df[\"text\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4b1e12-8b86-472f-9ad1-3391bf845efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AFTER TOKENIZATION ===\n",
      "0    [bromwell, high, is, a, cartoon, comedy, it, r...\n",
      "1    [homelessness, or, houselessness, as, george, ...\n",
      "2    [brilliant, overacting, by, lesley, ann, warre...\n",
      "3    [this, is, easily, the, most, underrated, film...\n",
      "4    [this, is, not, the, typical, mel, brooks, fil...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Split each message into individual tokens\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(word_tokenize)\n",
    "print(\"\\n=== AFTER TOKENIZATION ===\")\n",
    "print(train_df[\"text\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f8696c-f102-49ba-8d52-5f4087699a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AFTER REMOVING STOP WORDS ===\n",
      "0    [bromwell, high, cartoon, comedy, ran, time, p...\n",
      "1    [homelessness, houselessness, george, carlin, ...\n",
      "2    [brilliant, overacting, lesley, ann, warren, b...\n",
      "3    [easily, underrated, film, inn, brooks, cannon...\n",
      "4    [typical, mel, brooks, film, much, less, slaps...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Define a set of English stop words and remove them from the tokens\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "print(\"\\n=== AFTER REMOVING STOP WORDS ===\")\n",
    "print(train_df[\"text\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa23bbb8-d9de-459a-a798-1ecff5a3ab0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AFTER STEMMING ===\n",
      "0    [bromwel, high, cartoon, comedi, ran, time, pr...\n",
      "1    [homeless, houseless, georg, carlin, state, is...\n",
      "2    [brilliant, overact, lesley, ann, warren, best...\n",
      "3    [easili, underr, film, inn, brook, cannon, sur...\n",
      "4    [typic, mel, brook, film, much, less, slapstic...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Stem each token to reduce words to their base form ex. programming will turn into program\n",
    "stemmer = PorterStemmer()\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "print(\"\\n=== AFTER STEMMING ===\")\n",
    "print(train_df[\"text\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "084f3a7c-0db4-4d55-847c-abb38ba4d531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AFTER JOINING TOKENS BACK INTO STRINGS ===\n",
      "0    bromwel high cartoon comedi ran time program s...\n",
      "1    homeless houseless georg carlin state issu yea...\n",
      "2    brilliant overact lesley ann warren best drama...\n",
      "3    easili underr film inn brook cannon sure flaw ...\n",
      "4    typic mel brook film much less slapstick movi ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Rejoin tokens into a single string for feature extraction\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(lambda x: \" \".join(x))\n",
    "print(\"\\n=== AFTER JOINING TOKENS BACK INTO STRINGS ===\")\n",
    "print(train_df[\"text\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae95f2f-7ab6-46f6-bab4-ffa68a194210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTTON\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer with bigrams, min_df, and max_df to focus on relevant terms\n",
    "vectorizer = CountVectorizer(min_df=1, max_df=0.9, ngram_range=(1, 3))\n",
    "\n",
    "# Fit and transform the message column\n",
    "X = vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "# Labels (target variable)\n",
    "y = train_df[\"label\"] # Converting labels to 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ce0892-6b87-44dd-9416-db59f640b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Build the pipeline by combining vectorization and classification\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vectorizer),\n",
    "    (\"classifier\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "722e0af5-02a9-4ef4-8b92-ae0925df8b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: {'classifier__alpha': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"classifier__alpha\": [0.01, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "# Perform the grid search with 5-fold cross-validation and the F1-score as metric\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "# Fit the grid search on the full dataset\n",
    "grid_search.fit(train_df[\"text\"], y)\n",
    "\n",
    "# Extract the best model identified by the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best model parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1144e4aa-981b-4717-8d33-c143944d2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Evaluation\n",
    "\n",
    "test_df = pd.read_json(\"skills_assessment_data/test.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7ae56b5-2816-4ab3-babc-f247f519db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Preprocess function that mirrors the training-time preprocessing\n",
    "def preprocess_test_df(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s$!]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adc2352a-6dce-4a9d-bc8b-484ca42f3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and vectorize messages\n",
    "processed_test_df = [preprocess_test_df(msg) for msg in test_df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "098ac973-40ef-4ef7-8c5c-a5892badce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform preprocessed messages into feature vectors\n",
    "X_new = best_model.named_steps[\"vectorizer\"].transform(processed_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc285fe6-983a-46e5-85c5-60652892209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the trained classifier\n",
    "predictions = best_model.named_steps[\"classifier\"].predict(X_new)\n",
    "prediction_probabilities = best_model.named_steps[\"classifier\"].predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6443c62a-bc82-48e0-9011-39049ad3e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86     12500\n",
      "           1       0.88      0.82      0.85     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.86      0.86      0.86     25000\n",
      "weighted avg       0.86      0.86      0.86     25000\n",
      "\n",
      "\n",
      "Review: I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that...\n",
      "Prediction: Positive Review\n",
      "Positive Probability: 1.00\n",
      "Negative Probability: 0.00\n",
      "\n",
      "Review: Actor turned director Bill Paxton follows up his promising debut, the Gothic-horror \"Frailty\", with ...\n",
      "Prediction: Positive Review\n",
      "Positive Probability: 1.00\n",
      "Negative Probability: 0.00\n",
      "\n",
      "Review: As a recreational golfer with some knowledge of the sport's history, I was pleased with Disney's sen...\n",
      "Prediction: Positive Review\n",
      "Positive Probability: 1.00\n",
      "Negative Probability: 0.00\n",
      "\n",
      "Review: I saw this film in a sneak preview, and it is delightful. The cinematography is unusually creative, ...\n",
      "Prediction: Positive Review\n",
      "Positive Probability: 1.00\n",
      "Negative Probability: 0.00\n",
      "\n",
      "Review: Bill Paxton has taken the true story of the 1913 US golf open and made a film that is about much mor...\n",
      "Prediction: Positive Review\n",
      "Positive Probability: 1.00\n",
      "Negative Probability: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(test_df[\"label\"], predictions))\n",
    "print(classification_report(test_df[\"label\"], predictions))\n",
    "\n",
    "# Show a few predictions with probabilities\n",
    "for i in range(5):  # just first 5 examples\n",
    "    msg = test_df[\"text\"].iloc[i]\n",
    "    prediction = \"Positive Review\" if predictions[i] == 1 else \"Negative Review\"\n",
    "    positive_probability = prediction_probabilities[i][1]\n",
    "    negative_probability = prediction_probabilities[i][0]\n",
    "\n",
    "    print(f\"\\nReview: {msg[:100]}...\")  # truncate long reviews\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"Positive Probability: {positive_probability:.2f}\")\n",
    "    print(f\"Negative Probability: {negative_probability:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8414c5b1-39e4-48ed-832d-c74076017d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to skills_assessment.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file for future use\n",
    "model_filename = 'skills_assessment.joblib'\n",
    "joblib.dump(best_model, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1287d07-a85f-46c4-b5e7-6263dc58e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(model_filename)\n",
    "predictions = loaded_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1b0ae-60f1-4d77-b767-69b318729b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
